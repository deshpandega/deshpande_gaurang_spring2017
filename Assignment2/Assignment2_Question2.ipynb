{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "#### Read all json files\n",
    "#### find all \"terms\"\n",
    "#### Create folder hierarchy\n",
    "#### Store json files into respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, glob, os, csv, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to create the parent folder data_processed\n",
    "#Takes relative path and creates folder if it does not exist\n",
    "def create_parent_directory():\n",
    "    current_dir = os.path.dirname('__file__')\n",
    "    home_folder = os.path.join(current_dir, 'Data Processed')\n",
    "    if not os.path.exists(home_folder):\n",
    "        os.mkdir(home_folder)\n",
    "    return home_folder\n",
    "\n",
    "#Function to create folder structure by joining the input parameters and return the folder path\n",
    "#If folder is already created, return its path\n",
    "def make_directory_with_country(home_folder, country_name, city_name, term, category):\n",
    "    directory =os.path.join(home_folder, country_name, city_name, term, category)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return directory\n",
    "    else:\n",
    "        return directory\n",
    "\n",
    "#Function to write data to json file at respective location\n",
    "def write_to_json_file(file_path, json_data):\n",
    "    with open(file_path, 'w') as json_out:\n",
    "        json.dump(json_data, json_out)\n",
    "        \n",
    "#Lambda expression to remove numbers\n",
    "remove_numbers_lam = lambda value: re.sub(r'\\d+', '', value).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_folder = create_parent_directory()\n",
    "#Read all the json files at location using glob\n",
    "for filename in glob.glob(r'C:\\Users\\infer\\Desktop\\Spring17\\Python\\lectures\\DataAnalysis4Python_Spring17\\Assignment 2\\Data\\*.json'):\n",
    "    \n",
    "    #Get the file name currently reading\n",
    "    file_name = os.path.basename(filename)\n",
    "    with open(filename) as f:\n",
    "        \n",
    "        #Load data from json file\n",
    "        data_from_file = json.load(f)\n",
    "        \n",
    "        #Get all categories\n",
    "        categories = [category[\"title\"] for category in data_from_file[\"categories\"]]\n",
    "        for category in categories:\n",
    "            \n",
    "            #Remove multiple spaces with single space. For ex: \"New York\" and \"New  York\"\n",
    "            category = ' '.join(category.split())\n",
    "            \n",
    "            #Remove extra spaces and numbers from city names\n",
    "            city_name = ' '.join((data_from_file[\"location\"][\"city\"]).split())\n",
    "            city_name = remove_numbers_lam(city_name)\n",
    "            \n",
    "            #Call function to get folder path\n",
    "            data_dir = make_directory_with_country(home_folder, data_from_file[\"location\"][\"country\"], city_name, data_from_file[\"term\"], category)\n",
    "            \n",
    "            #Create file path by joining folder structure and file name\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            \n",
    "            #Write to json file\n",
    "            write_to_json_file(file_path, data_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 End Result:\n",
    "\n",
    "##### The categorization is done like follow:\n",
    "\n",
    "##### Data Processed > Country > City > Type > Category > File.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "#### Read all json files\n",
    "#### find all \"restaurants\"\n",
    "#### Get timing for each restaurant for each day\n",
    "#### Store results in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to write data for each restaurant for each day in separate row\n",
    "def add_rows(file, details):\n",
    "    rows = []\n",
    "    for detail in details:\n",
    "        row = []\n",
    "        row.append(file[\"name\"])\n",
    "        row.append(' '.join((file[\"location\"][\"city\"]).split()))\n",
    "        row.append(file[\"location\"][\"country\"])\n",
    "        row.append(detail['day'])\n",
    "        row.append(detail['start'][:2])\n",
    "        row.append(detail['start'][2:])\n",
    "        row.append(detail['end'][:2])\n",
    "        row.append(detail['end'][2:])\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "#Function to write data to given csv file\n",
    "def write_to_csv(file_name, restaurant_timings):\n",
    "    \n",
    "    #Use utf-8 encoding because of some restaurant names are not in english letters\n",
    "    with open(file_name, 'w', encoding='utf-8') as csv_output:\n",
    "        \n",
    "        #Use escapechar to separate the delimiter and words\n",
    "        writer = csv.writer(csv_output, delimiter=',', quoting=csv.QUOTE_NONE, lineterminator='\\n',escapechar='\\\\')\n",
    "        \n",
    "        #Title row\n",
    "        writer.writerow((\"Name of Restaurant\", 'City', 'Country Code', 'Day of Week', 'Start Time Hour', 'Start Time Minutes', 'End Time Hour', 'End Time Minutes'))\n",
    "        for row in restaurant_timings:\n",
    "            writer.writerow(row)\n",
    "    \n",
    "        #Close connection\n",
    "        csv_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read all the json files at location using glob\n",
    "restaurant_timings = []\n",
    "for filename in glob.glob(r'C:\\Users\\infer\\Desktop\\Spring17\\Python\\lectures\\DataAnalysis4Python_Spring17\\Assignment 2\\Data\\*.json'):\n",
    "    with open(filename) as f:\n",
    "        \n",
    "        #Load data from json file\n",
    "        data_from_file = json.load(f)\n",
    "        \n",
    "        #Check if the place is a restaurant\n",
    "        if data_from_file[\"term\"] == 'restaurants':\n",
    "            \n",
    "            #Check if there are hours mentioned for a restaurant\n",
    "            try:\n",
    "                details = [value for value in data_from_file[\"hours\"]]\n",
    "            \n",
    "            #Create a dummy row to populate the data in case if it is not present\n",
    "            except:\n",
    "                details = [{\"open\":[{\"day\": \"NA\",\"start\": \"NANA\",\"end\": \"NANA\"}]}]\n",
    "                \n",
    "            #Populate the data in a list\n",
    "            restaurant_timings.extend(add_rows(data_from_file, details[0][\"open\"]))\n",
    "            \n",
    "write_to_csv('restaurant_timings.csv', restaurant_timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
