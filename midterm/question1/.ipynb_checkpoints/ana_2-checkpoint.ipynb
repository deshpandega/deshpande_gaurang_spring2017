{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Analysis 2\n",
    "#### Use a list of suspected words that people have used in stemmed format\n",
    "#### Check sent, delete and inbox folders of all people and get the payload of all the emails in these folders.\n",
    "#### Remove numbers, punctuations and blank quotes from message body. Use nltk word_tokenize to tokanize the email body and  Porter Stemmer to stem the words from email body.\n",
    "#### Check if any email has used these suspected words. If they are present, get the person whose mail box we just scanned.\n",
    "#### In a dictionary, store name of person as key and list of all suspected emails sent/received or deleted as value\n",
    "#### Save dictionary in json file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import json, os, glob, email, fnmatch, string, nltk, re, operator\n",
    "from email.message import EmailMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the data for emails\n",
    "current_dir = os.path.dirname('__file__')\n",
    "data_dir = os.path.join(current_dir, '..', 'data','enron')\n",
    "\n",
    "matches = []\n",
    "for root, dirnames, filenames in os.walk(data_dir):\n",
    "    for filename in fnmatch.filter(filenames, '*'):\n",
    "        matches.append(os.path.join(root, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To remove puctuations\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#Create a list of suspected words in stem format \n",
    "suspected_words = ['off-balance-sheet', 'special purpose vehicles', 'SPV', 'special purposes entities', 'SPE', 'balance sheet', 'Arthur Andersen', 'Duncan', 'investig','bankruptci','fraud','feder prosecut','shred','scandal','conspiraci','insid trade']\n",
    "count = 0\n",
    "porter = nltk.PorterStemmer()\n",
    "message_of_interest=[]\n",
    "\n",
    "#Iterate over all the emails \n",
    "for filename in matches:\n",
    "    #Consider only emails sent, received or deleted\n",
    "    if 'sent' in filename or 'delete' in filename or 'inbox' in filename:    \n",
    "        with open(filename,'r') as f:\n",
    "            data_from_file =  f.read()\n",
    "            message = email.message_from_string(data_from_file)\n",
    "            \n",
    "            #Get the payload of email\n",
    "            words = nltk.word_tokenize(message.get_payload())\n",
    "            \n",
    "            #Tokanize the message\n",
    "            tok = [word.translate(translator) for word in words]\n",
    "            \n",
    "            #Remove punctuations, numbers and blank quotes\n",
    "            tokens = [re.sub(r'\\d+', '', toke) for toke in tok if toke !='']\n",
    "            \n",
    "            #Use Porter stemmer method to stem the words\n",
    "            try:\n",
    "                list_of_words = [porter.stem(t) for t in tokens]\n",
    "            except:\n",
    "                list_of_words = tokens\n",
    "                \n",
    "            #Compare the words if any one matches with suspected words\n",
    "            for single_word in list_of_words:\n",
    "                if single_word in  suspected_words:\n",
    "                    message_of_interest.append(message)             #Save the entire message in a list to work on later\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "suspected_people = {}\n",
    "#Get the name of people who used those words in a dictionary as key and the details of that email in a list as value\n",
    "for message in message_of_interest:\n",
    "    list_of_details_mailed = [message['From'], message['To'], message['Date'], message['Message-ID'], message.get_payload()]\n",
    "    if message['X-Origin'].title() not in suspected_people:\n",
    "        suspected_people[message['X-Origin'].title()] = [list_of_details_mailed]\n",
    "    else:\n",
    "        suspected_people[message['X-Origin'].title()] += [list_of_details_mailed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sort the dictionary according to person name\n",
    "sorted_mails_dict = sorted(suspected_people.items(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to write the data into a json file\n",
    "def write_to_json_file(file_path, json_data):\n",
    "    with open(file_path, 'w') as json_out:\n",
    "        json.dump(json_data, json_out, indent=2)\n",
    "\n",
    "#Function to create the relative path\n",
    "def create_directory_for_output():\n",
    "    current_dir = os.path.dirname('__file__')\n",
    "    data_folder = os.path.join(current_dir, 'ana_2')\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.mkdir(data_folder)\n",
    "    return data_folder\n",
    "\n",
    "output_folder=create_directory_for_output()\n",
    "\n",
    "#Name of json file storing suspected people and the respective emails\n",
    "file_name = 'suspected_users_by_email'\n",
    "file_path = os.path.join(output_folder, file_name)\n",
    "file_path+='.json'\n",
    "\n",
    "#Write data to file\n",
    "write_to_json_file(file_path, sorted_mails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
